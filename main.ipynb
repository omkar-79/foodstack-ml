{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from datetime import datetime, timedelta\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dishes\n",
    "dishes = [\"Burger\", \"Pizza\", \"Sandwich\", \"Pasta\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_hourly_orders(hour, dish_index):\n",
    "    \"\"\"\n",
    "    Simulate actual data for a dish based on day, hour, and randomness.\n",
    "    \"\"\"\n",
    "    base_demand = {\n",
    "        0: 50,  # Burger base demand\n",
    "        1: 40,  # Pizza base demand\n",
    "        2: 30,  # Sandwich base demand\n",
    "        3: 20,  # Pasta base demand\n",
    "    }\n",
    "    # Adjust demand by hour of day (higher during lunch/dinner hours)\n",
    "    if 11 <= hour <= 14 or 18 <= hour <= 21:\n",
    "        return int(base_demand[dish_index] * random.uniform(0.8, 1.2))\n",
    "    else:\n",
    "        return int(base_demand[dish_index] * random.uniform(0.4, 0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate actual data with Date\n",
    "def simulate_actual_data(start_date, num_days, dishes):\n",
    "    \"\"\"\n",
    "    Generate actual data with 'Date', 'Hour', 'Dish', and 'Amount Ordered'.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for day_offset in range(num_days):\n",
    "        current_date = start_date + timedelta(days=day_offset)\n",
    "        day_of_week = current_date.weekday()  # 0 = Monday, ..., 6 = Sunday\n",
    "        for hour in range(24):\n",
    "            for dish_index, dish in enumerate(dishes):\n",
    "                # Simulate amount ordered\n",
    "                amount = simulate_hourly_orders(hour, dish_index)\n",
    "                data.append([current_date, day_of_week, hour, dish_index, amount])\n",
    "    return pd.DataFrame(data, columns=[\"Date\", \"Day\", \"Hour\", \"Dish\", \"Amount Ordered\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate actual data for 7 days\n",
    "start_date = datetime(2025, 1, 1)  # Start on January 1, 2025\n",
    "num_days = 7\n",
    "actual_data = simulate_actual_data(start_date, num_days, dishes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Dish</th>\n",
       "      <th>Amount Ordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>2025-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>2025-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>2025-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>2025-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>2025-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>2025-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Day  Hour  Dish  Amount Ordered\n",
       "572 2025-01-06    0    23     0              21\n",
       "573 2025-01-06    0    23     1              19\n",
       "574 2025-01-06    0    23     2              16\n",
       "575 2025-01-06    0    23     3               8\n",
       "576 2025-01-07    1     0     0              23\n",
       "..         ...  ...   ...   ...             ...\n",
       "667 2025-01-07    1    22     3              10\n",
       "668 2025-01-07    1    23     0              25\n",
       "669 2025-01-07    1    23     1              17\n",
       "670 2025-01-07    1    23     2              12\n",
       "671 2025-01-07    1    23     3               8\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_data.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data for the model\n",
    "X = actual_data[[\"Day\", \"Hour\", \"Dish\"]]\n",
    "y = actual_data[\"Amount Ordered\"]\n",
    "\n",
    "# Split into training (first 6 days) and test (last day for predictions)\n",
    "train_data = actual_data[actual_data[\"Date\"] < start_date + timedelta(days=6)]\n",
    "test_data = actual_data[actual_data[\"Date\"] >= start_date + timedelta(days=6)]\n",
    "\n",
    "X_train = train_data[[\"Day\", \"Hour\", \"Dish\"]]\n",
    "y_train = train_data[\"Amount Ordered\"]\n",
    "\n",
    "X_test = test_data[[\"Day\", \"Hour\", \"Dish\"]]\n",
    "y_test = test_data[\"Amount Ordered\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Continuous training setup (SGDRegressor)\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"day_hour\", StandardScaler(), [\"Day\", \"Hour\"]),\n",
    "        (\"dish\", OneHotEncoder(), [\"Dish\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create pipeline\n",
    "sgd_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", SGDRegressor(max_iter=1000, tol=1e-3, learning_rate=\"adaptive\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous learning function\n",
    "def continuous_training_pipeline(initial_data, pipeline, prediction_horizon=7):\n",
    "    \"\"\"\n",
    "    Perform continuous training and prediction with separate prediction dataset.\n",
    "    \"\"\"\n",
    "    # Initialize training data (first 7 days)\n",
    "    X_train = initial_data[[\"Day\", \"Hour\", \"Dish\"]]\n",
    "    y_train = initial_data[\"Amount Ordered\"]\n",
    "    \n",
    "    # Train the model on the initial 7 days\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print(\"Initial training complete.\")\n",
    "    \n",
    "    # Create a prediction dataset for the next 7 days\n",
    "    current_date = initial_data[\"Date\"].max()\n",
    "    prediction_data = []\n",
    "    for day_offset in range(1, prediction_horizon + 1):\n",
    "        prediction_date = current_date + timedelta(days=day_offset)\n",
    "        day_of_week = prediction_date.weekday()\n",
    "        for hour in range(24):\n",
    "            for dish_index, dish in enumerate(dishes):\n",
    "                prediction_data.append([prediction_date, day_of_week, hour, dish_index])\n",
    "    prediction_data = pd.DataFrame(prediction_data, columns=[\"Date\", \"Day\", \"Hour\", \"Dish\"])\n",
    "    prediction_data[\"Predicted Amount\"] = pipeline.predict(prediction_data[[\"Day\", \"Hour\", \"Dish\"]])\n",
    "    \n",
    "    print(\"\\nInitial Predictions:\")\n",
    "    print(prediction_data)\n",
    "    \n",
    "    # Simulate continuous training\n",
    "    while True:\n",
    "        # Simulate receiving actual data for the next day\n",
    "        actual_date = current_date + timedelta(days=1)\n",
    "        actual_data = simulate_actual_data(actual_date, 1, dishes)\n",
    "        \n",
    "        # Compare actual data with predictions\n",
    "        comparison = pd.merge(actual_data, prediction_data, on=[\"Day\", \"Hour\", \"Dish\"], suffixes=(\"_Actual\", \"_Predicted\"))\n",
    "        print(f\"\\nComparison for {actual_date}:\")\n",
    "        print(comparison)\n",
    "        \n",
    "        # Update the model with the actual data\n",
    "        X_actual = actual_data[[\"Day\", \"Hour\", \"Dish\"]]\n",
    "        y_actual = actual_data[\"Amount Ordered\"]\n",
    "        pipeline.named_steps[\"regressor\"].partial_fit(X_actual, y_actual)\n",
    "        print(f\"Model updated with actual data for {actual_date}.\")\n",
    "        \n",
    "        # Update predictions for the next 7 days\n",
    "        prediction_data = []\n",
    "        for day_offset in range(1, prediction_horizon + 1):\n",
    "            prediction_date = actual_date + timedelta(days=day_offset)\n",
    "            day_of_week = prediction_date.weekday()\n",
    "            for hour in range(24):\n",
    "                for dish_index, dish in enumerate(dishes):\n",
    "                    prediction_data.append([prediction_date, day_of_week, hour, dish_index])\n",
    "        prediction_data = pd.DataFrame(prediction_data, columns=[\"Date\", \"Day\", \"Hour\", \"Dish\"])\n",
    "        prediction_data[\"Predicted Amount\"] = pipeline.predict(prediction_data[[\"Day\", \"Hour\", \"Dish\"]])\n",
    "        print(f\"\\nUpdated Predictions:\")\n",
    "        print(prediction_data)\n",
    "        \n",
    "        # Move to the next day\n",
    "        current_date = actual_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 14 days of data (7 for initial training + simulate next days)\n",
    "start_date = datetime(2025, 1, 1)\n",
    "all_data = simulate_actual_data(start_date, 14, dishes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into initial training data (7 days)\n",
    "initial_data = all_data[all_data[\"Date\"] < start_date + timedelta(days=7)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial training complete.\n",
      "\n",
      "Predictions for 2025-01-08 00:00:00 to 2025-01-14 00:00:00:\n",
      "     Day  Hour  Dish  Predicted Amount\n",
      "0      2     0     0         26.603633\n",
      "1      2     0     1         19.670511\n",
      "2      2     0     2         13.047567\n",
      "3      2     0     3          6.528882\n",
      "4      2     1     0         27.157738\n",
      "..   ...   ...   ...               ...\n",
      "667    1    22     3         18.683897\n",
      "668    1    23     0         39.312753\n",
      "669    1    23     1         32.379632\n",
      "670    1    23     2         25.756688\n",
      "671    1    23     3         19.238003\n",
      "\n",
      "[672 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omkar/Documents/Project/foodstack-ml/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but SGDRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 3 features, but SGDRegressor is expecting 6 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run the continuous training pipeline\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcontinuous_training_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msgd_pipeline\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 42\u001b[0m, in \u001b[0;36mcontinuous_training_pipeline\u001b[0;34m(initial_data, pipeline, prediction_horizon)\u001b[0m\n\u001b[1;32m     40\u001b[0m X_actual \u001b[38;5;241m=\u001b[39m actual_data[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDay\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHour\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDish\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     41\u001b[0m y_actual \u001b[38;5;241m=\u001b[39m actual_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAmount Ordered\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 42\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamed_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mregressor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_actual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_actual\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Fix: Access the regressor step\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel updated with actual data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactual_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Update current_date to the next day\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Project/foodstack-ml/.venv/lib/python3.13/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Project/foodstack-ml/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:1543\u001b[0m, in \u001b[0;36mBaseSGDRegressor.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoef_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1541\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_more_validate_params(for_partial_fit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 1543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partial_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1546\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Project/foodstack-ml/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:1467\u001b[0m, in \u001b[0;36mBaseSGDRegressor._partial_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[1;32m   1453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_partial_fit\u001b[39m(\n\u001b[1;32m   1454\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1455\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1464\u001b[0m     intercept_init,\n\u001b[1;32m   1465\u001b[0m ):\n\u001b[1;32m   1466\u001b[0m     first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoef_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1467\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1471\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1477\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1478\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mastype(X\u001b[38;5;241m.\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m first_call:\n\u001b[1;32m   1481\u001b[0m         \u001b[38;5;66;03m# TODO(1.7) remove 0 from average parameter constraint\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Project/foodstack-ml/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2965\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m-> 2965\u001b[0m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Documents/Project/foodstack-ml/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2829\u001b[0m, in \u001b[0;36m_check_n_features\u001b[0;34m(estimator, X, reset)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m-> 2829\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2830\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2831\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2832\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 3 features, but SGDRegressor is expecting 6 features as input."
     ]
    }
   ],
   "source": [
    "# Run the continuous training pipeline\n",
    "continuous_training_pipeline(initial_data, sgd_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for the next 7 days\n",
    "future_days = 7\n",
    "future_data = []\n",
    "for future_day_offset in range(7):\n",
    "    future_date = start_date + timedelta(days=6 + future_day_offset)\n",
    "    future_day_of_week = future_date.weekday()\n",
    "    for hour in range(24):\n",
    "        for dish_index, dish in enumerate(dishes):\n",
    "            future_data.append([future_day_of_week, hour, dish_index])\n",
    "\n",
    "future_df = pd.DataFrame(future_data, columns=[\"Day\", \"Hour\", \"Dish\"])\n",
    "future_predictions = sgd_pipeline.predict(future_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions for Next 7 Days:\n",
      "    Day  Hour  Dish  Predicted Amount\n",
      "0    1     0     0         26.364147\n",
      "1    1     0     1         19.422799\n",
      "2    1     0     2         13.194011\n",
      "3    1     0     3          6.187893\n",
      "4    1     1     0         26.936111\n"
     ]
    }
   ],
   "source": [
    "# Add predictions to the future dataset\n",
    "future_df[\"Predicted Amount\"] = future_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions for Next 7 Days:\n",
      "     Day  Hour  Dish  Predicted Amount\n",
      "0     1     0     0         26.364147\n",
      "1     1     0     1         19.422799\n",
      "2     1     0     2         13.194011\n",
      "3     1     0     3          6.187893\n",
      "4     1     1     0         26.936111\n",
      "5     1     1     1         19.994763\n",
      "6     1     1     2         13.765976\n",
      "7     1     1     3          6.759857\n",
      "8     1     2     0         27.508075\n",
      "9     1     2     1         20.566727\n",
      "10    1     2     2         14.337940\n",
      "11    1     2     3          7.331822\n",
      "12    1     3     0         28.080039\n",
      "13    1     3     1         21.138691\n",
      "14    1     3     2         14.909904\n",
      "15    1     3     3          7.903786\n",
      "16    1     4     0         28.652003\n",
      "17    1     4     1         21.710655\n",
      "18    1     4     2         15.481868\n",
      "19    1     4     3          8.475750\n"
     ]
    }
   ],
   "source": [
    "# Display predictions for the next 7 days\n",
    "print(\"\\nPredictions for Next 7 Days:\\n\", future_df.head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
